# Principles of Machine Learning in Python

This course is offered by Microsoft and officially available on [EdX](https://www.edx.org/course/principles-of-machine-learning-python-edition-4)[.](https://github.com/MicrosoftLearning/Principles-of-Machine-Learning-Python)

However, I have added multiple new features in some of the notebooks to make it easier to understand as well as visualize.

# Course Syllabus
- Introduction to Machine Learning
- Exploring Data
- Data Preparation and Cleaning
- Getting Started with Supervised Learning
- Improving Model Performance
- Machine Learning Algorithms
- Unsupervised Learning

# Notebooks   

- IntroductionToMachineLearning
    - KNN Classification

- VisualizingDataForClassification
    - Box plot, Violin plot

- VisualizingDataForRegression
    - Box plot, Violin plot
    - Combined Histogram, KDEs, 2D density plot, Pair plot

- DataPreparation
    - Feature Engineering

- ApplyingLinearRegression

- Classification
    - Confusion matrix, Accuracy, Precision, Recall, F1, ROC, AUC
    - Weighted Model

- IntroductionToRegression
    - Errors: MSE, RMSE, Mean(Median) Absolute Error
    - R Squared, adjusted R Squared

- Bias-Variance-Trade-Off
    - L1, L2 Regularization

- CrossValidation
    - K-Fold Cross Validation
    - Nested Cross Validation

- DimensionalityReduction
    - Principle component analysis

- FeatureSelection
    - Eliminate Low Variance Features
    - Select k best features

- Bagging
    - Random Forest Model

- Boosting

- NaiveBayes
    - Gaussian, Bernoulli, Multinomial
     
- NeuralNetworks
    - Optimal Hyperparameters

- SupportVectorMachines
    - Linear Kernel, Radial Basis Function (RBF) Kernel

- ApplicationOfClustering
    - Kmeans Clustering
    - Agglomerative Clustering

- IntroToUnsupervisedLearning
    - Kmeans Clustering
    - Hierarchical Clustering: Linkage Distance (ward, average, complete)

